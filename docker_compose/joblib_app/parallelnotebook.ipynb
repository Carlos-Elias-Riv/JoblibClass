{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computate to the value 1136.5969161564717 in 14 iterations\n"
     ]
    }
   ],
   "source": [
    "with Parallel(n_jobs=-1) as parallel:\n",
    "    def sqrt(x):\n",
    "        return x**0.5\n",
    "    \n",
    "    accumulator = 0.\n",
    "    n_iter = 0\n",
    "    while accumulator < 1000:\n",
    "        results = parallel(delayed(sqrt) (accumulator + i **2) for i in range(5))\n",
    "        accumulator += sum(results)\n",
    "        n_iter += 1\n",
    "        \n",
    "    print(f'Computate to the value {accumulator} in {n_iter} iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computate to the value 1136.5969161564717 in 14 iterations\n"
     ]
    }
   ],
   "source": [
    "accumulator = 0.\n",
    "n_iter = 0\n",
    "while accumulator < 1000: \n",
    "    results = 0.\n",
    "    for i in range(5): \n",
    "        results += sqrt(accumulator + i**2)\n",
    "    accumulator += (results)\n",
    "    n_iter += 1\n",
    "        \n",
    "print(f'Computate to the value {accumulator} in {n_iter} iterations')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Entendiendo los diferentes tipos de backend de joblib con aleatoriedad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Primero vamos a ver que pasa al correr de manera secuencial un experimento con aleatoriedad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The different generated vectors in a sequential manner are: \n",
      "[[13 10  9 14  6]\n",
      " [ 0  1 11  4 13]\n",
      " [ 9 11 12  6  8]\n",
      " [11 11  8  1 11]\n",
      " [ 5  7  6  2  3]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def printvector(vector, backend):\n",
    "    print(f'\\nThe different generated vectors using the {backend} backend are:\\n { np.array(vector)}')\n",
    "\n",
    "def generarcoordenadas(max):\n",
    "    return np.random.randint(max, size = 5)\n",
    "\n",
    "nvectors = 5\n",
    "\n",
    "randomvector = [generarcoordenadas(15) for i in range(nvectors)]\n",
    "\n",
    "print(f'\\nThe different generated vectors in a sequential manner are: \\n{np.array(randomvector)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Luego vamos a ver que pasa con backend = 'loky' y 'threading'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The different generated vectors using the loky backend are:\n",
      " [[10  0  8  9  8]\n",
      " [ 2  7  5  5  5]\n",
      " [ 0  6  8  3  1]\n",
      " [14  7  0 13  2]\n",
      " [14  1  3  7 11]]\n",
      "\n",
      "The different generated vectors using the threading backend are:\n",
      " [[ 1  1  9  6  3]\n",
      " [13 10 13  9  6]\n",
      " [ 1 14  0  8  9]\n",
      " [14  2 14 12  3]\n",
      " [10  3  7  3 14]]\n"
     ]
    }
   ],
   "source": [
    "backend = 'loky'\n",
    "random_vector = Parallel(n_jobs=4, backend=backend)(delayed(\n",
    "    generarcoordenadas)(15) for _ in range(nvectors))\n",
    "printvector(random_vector, backend)\n",
    "\n",
    "backend = 'threading'\n",
    "random_vector = Parallel(n_jobs=4, backend=backend)(delayed(generarcoordenadas)(15) for _ in range(nvectors))\n",
    "printvector(random_vector, backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observemos que en estos casos la paralelización preserva aleatoriedad, pasemos ahora a multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The different generated vectors using the multiprocessing backend are:\n",
      " [[13 13  2  0 12]\n",
      " [13 13  2  0 12]\n",
      " [13 13  2  0 12]\n",
      " [13 13  2  0 12]\n",
      " [13 13  2  0 12]\n",
      " [ 5 14  1  8  5]\n",
      " [ 5 14  1  8  5]\n",
      " [ 5 14  1  8  5]\n",
      " [ 5 14  1  8  5]\n",
      " [11  4  0  1 11]]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "backend = 'multiprocessing'\n",
    "nvectors = 10\n",
    "def generarcoordenadas(max):\n",
    "    seed = np.random.randint(1000) # add a random seed value\n",
    "    return np.random.RandomState(seed).randint(max, size=5)\n",
    "\n",
    "\n",
    "random_vector = Parallel(n_jobs = 5, backend = backend)( delayed(generarcoordenadas)(15) for i in range(nvectors))\n",
    "printvector(random_vector, backend)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### YA NO SE CUMPLE la aleatoriedad, observemos que obtendremos nvectors // n_jobs grupos iguales lo cual muestra que la aleatoriedad ya no se está cumpliendo esto sucede porque el estado global del generador de números aleatorios de numpy se duplicará exactamente en todos los trabajadores. Es decir todos tienen la misma random seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esto podemos arreglarlo cambiando el estado de generador de números aleatorios usando RandomState y seeds que lo cambien por cada proceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The different generated vectors using the multiprocessing backend are:\n",
      " [[10 10  2 14  6]\n",
      " [ 6 12  8  8 10]\n",
      " [ 5  4  4 10  5]\n",
      " [ 9  2  1 11  7]\n",
      " [14  4 12 10  5]\n",
      " [ 2 14  1 11 14]\n",
      " [ 3 14 11 12 13]\n",
      " [ 3  3  8  7  4]\n",
      " [ 8 13  3 13  5]\n",
      " [14  3  6  0  8]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def printvector(vector, backend):\n",
    "    print(f'\\nThe different generated vectors using the {backend} backend are:\\n { np.array(vector)}')\n",
    "\n",
    "def generarcoordenadas(max, seed):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    return rng.randint(max, size=5)\n",
    "\n",
    "backend = 'multiprocessing'\n",
    "nvectors = 10\n",
    "\n",
    "\n",
    "random_vector = Parallel(n_jobs=5, backend=backend)(delayed(generarcoordenadas)(15, None) for i in range(nvectors))\n",
    "printvector(random_vector, backend)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diferencias entre joblib y multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos notado, tanto joblib como multiprocessing sirven para realizar procesos en paralelo empleando diferentes cores de nuestro CPU, sin embargo, entre ellas existen diferencias entre ambas librerías.\n",
    "### Nivel:\n",
    "- Multiprocessing: Librería de bajo nivel ==> Menos amigable para el usuario; mayor control y flexibilidad para con el proceso.\n",
    "- Joblib: Librería de alto nivel ==> API más fácil de utilizar, menor control e ingerencia del usuario en el proceder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empleo:\n",
    "- Multiprocessing: Aplicable a cualquier tipo de proceso de Python.\n",
    "- Joblib: Aplicable principalmente a procesos que involucren computación científica o numérica, o que, en general, solo utilicen el CPU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alcance:\n",
    "- Multiprocessing: Procesos más complejos que requieran de mayor control y flexibilidad. Ejemplo: Tasks que involucren I/O como lectura o escritura de archivos.\n",
    "- Joblib: Procesos más simples (solo requieren del CPU) que priorizan cachear los resultados. Ejemplo: Tasks con datasets muy extensos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codigo que ejemplicifica la diferencia de eficiencia entre joblib y multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing as mp\n",
    "\n",
    "# Define a function to be parallelized\n",
    "def square(x):\n",
    "    return x**2\n",
    "\n",
    "# Define the input data\n",
    "data = np.arange(100000)\n",
    "\n",
    "# Run the function using joblib\n",
    "start_time = time.time()\n",
    "result1 = Parallel(n_jobs=4)(delayed(square)(i) for i in data)\n",
    "joblib_time = time.time() - start_time\n",
    "\n",
    "# Run the function using multiprocessing\n",
    "start_time = time.time()\n",
    "pool = mp.Pool(processes=4)\n",
    "result2 = pool.map(square, data)\n",
    "multiprocessing_time = time.time() - start_time\n",
    "\n",
    "# Compare the results and time response\n",
    "print(\"Joblib result:\", result1[:10])\n",
    "print(\"Multiprocessing result:\", result2[:10])\n",
    "print(\"Joblib time:\", joblib_time)\n",
    "print(\"Multiprocessing time:\", multiprocessing_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busquemos la forma de aplicar Paralelización en dataframes, de manera que podamos iterar sobre las columnas para hacer operaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2\n",
      "0     1     6\n",
      "1     2     7\n",
      "2     3     8\n",
      "3     4     9\n",
      "4     5    10\n",
      "   col1  col2\n",
      "0     6     6\n",
      "1     7     7\n",
      "2     8     8\n",
      "3     9     9\n",
      "4    10    10\n",
      "   col1  col2\n",
      "0     6     6\n",
      "1     7     7\n",
      "2     8    10\n",
      "3     9    10\n",
      "4    10    10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'col1': [1, 2, 3, 4, 5],\n",
    "    'col2': [6, 7, 8, 9, 10]\n",
    "})\n",
    "\n",
    "columna1 = df['col1'].tolist()\n",
    "print(df)\n",
    "\n",
    "def sumar5(cell): \n",
    "    return cell +5\n",
    "\n",
    "resultados = Parallel(n_jobs=4)(delayed(sumar5)(cell) for cell in columna1)\n",
    "\n",
    "\n",
    "\n",
    "df['col1'] = resultados\n",
    "print(df)\n",
    "\n",
    "df.loc[df['col1']>= 8, 'col2'] = 10\n",
    "\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corriendo cosas de joblib con memoria compartida, es decir que varios procesos afecten a un mismo objeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [2, 3, 4, 5], 2: [1, 3, 5], 3: [1, 2, 5], 4: [1], 5: [1, 2, 3]}\n",
      "{1: [2, 3, 4], 2: [1, 3], 3: [1, 2], 4: [1], 5: []}\n"
     ]
    }
   ],
   "source": [
    "## Nuestro ejemplo es con un grafo\n",
    "from joblib import Parallel, delayed\n",
    "graph =  {1: [2,3, 4], \n",
    "          2: [1, 3],\n",
    "          3: [1, 2], \n",
    "          4: [1],\n",
    "          5: []}\n",
    "\n",
    "# Podemos hacer que todos los nodos menores o iguales a 3 estén conectados con el nodo 5, usando paralelización y memoria compartida\n",
    "\n",
    "def connect(node1, node2):\n",
    "    graph[node1].append(node2)\n",
    "    graph[node2].append(node1)\n",
    "    \n",
    "Parallel(n_jobs = 4, require = 'sharedmem')(\n",
    "        delayed(connect)(node, 5) for node in range(1,4))\n",
    "\n",
    "print(graph)\n",
    "\n",
    "## Volvamos a correr todo lo mismo pero sin memoria compartida y vemos que obtenemos un resultado distinto\n",
    "\n",
    "graph =  {1: [2,3, 4], \n",
    "          2: [1, 3],\n",
    "          3: [1, 2], \n",
    "          4: [1],\n",
    "          5: []}\n",
    "\n",
    "def connect(node1, node2):\n",
    "    graph[node1].append(node2)\n",
    "    graph[node2].append(node1)\n",
    "\n",
    "Parallel(n_jobs = 4)(\n",
    "    delayed(connect)(node, 5) for node in range(1, 4))\n",
    "\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
